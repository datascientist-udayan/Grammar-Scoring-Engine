{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52cc33f0",
   "metadata": {},
   "source": [
    "importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a566c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a5308c",
   "metadata": {},
   "source": [
    "The function extract_features is designed to extract a variety of audio features from an audio file using the librosa library. Hereâ€™s a breakdown of the features being extracted:\n",
    "\n",
    "1. MFCCs (Mel-frequency cepstral coefficients):\n",
    "\n",
    "The function computes the MFCCs of the audio signal, which are widely used in audio processing and speech recognition. The mean of the MFCCs is calculated and added to the feature list.\n",
    "\n",
    "2. Chroma Features:\n",
    "\n",
    "Chroma features represent the energy distribution across the 12 different pitch classes. The mean of these features is also calculated and added to the list.\n",
    "\n",
    "3. Mel Spectrogram:\n",
    "\n",
    "The Mel spectrogram is computed, which provides a representation of the short-term power spectrum of sound. The mean of the Mel spectrogram is included in the features.\n",
    "4. Spectral Contrast:\n",
    "\n",
    "This feature measures the difference in amplitude between peaks and valleys in the sound spectrum. The mean of the spectral contrast is added to the feature list.\n",
    "\n",
    "4. Tonnetz (Tonal centroid features):\n",
    "\n",
    "Tonnetz features capture the harmonic relations in music. The harmonic component of the audio signal is first extracted, and then the tonnetz features are computed and averaged.\n",
    "\n",
    "5. Zero Crossing Rate (ZCR):\n",
    "\n",
    "The ZCR measures how often the signal changes from positive to negative or back. The mean value is appended to the features.\n",
    "\n",
    "6. Root Mean Square Error (RMSE):\n",
    "\n",
    "RMSE provides a measure of the energy of the audio signal. The mean value of the RMSE is calculated and added to the feature list.\n",
    "\n",
    "The function returns a list of these extracted features, which can be used for further analysis, such as training machine learning models for tasks like classification or regression in audio processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedae81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(filepath):\n",
    "    y, sr = librosa.load(filepath, sr=None)\n",
    "    features = []\n",
    "\n",
    "    # MFCCs\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "    features.extend(np.mean(mfcc, axis=1))\n",
    "\n",
    "    # Chroma\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    features.extend(np.mean(chroma, axis=1))\n",
    "\n",
    "    # Mel Spectrogram\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    features.extend(np.mean(mel, axis=1))\n",
    "\n",
    "    # Spectral Contrast\n",
    "    contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    features.extend(np.mean(contrast, axis=1))\n",
    "\n",
    "    # Tonnetz\n",
    "    y_harmonic = librosa.effects.harmonic(y)\n",
    "    tonnetz = librosa.feature.tonnetz(y=y_harmonic, sr=sr)\n",
    "    features.extend(np.mean(tonnetz, axis=1))\n",
    "\n",
    "    # Zero Crossing Rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    features.append(np.mean(zcr))\n",
    "\n",
    "    # RMSE\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    features.append(np.mean(rmse))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ce778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape: (444, 195)\n"
     ]
    }
   ],
   "source": [
    "# LOAD & PROCESS TRAIN DATA\n",
    "train_df = pd.read_csv(\"dataset/train.csv\")  # Contains 'filename' & 'label'\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i, row in train_df.iterrows():\n",
    "    path = f\"dataset/audios_train/{row['filename']}\"\n",
    "    feats = extract_features(path)\n",
    "    X.append(feats)\n",
    "    y.append(row[\"label\"])\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "\n",
    "print(\"Train features shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd8a5c2",
   "metadata": {},
   "source": [
    " initializes a RandomizedSearchCV for a RandomForestRegressor with specified hyperparameters, fits the model to the training data, and retrieves the best hyperparameters found during the search, all in one expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe23bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Params: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 20, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "#TRAIN-TEST SPLIT & HYPERPARAMETER TUNING\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_distributions=param_dist, n_iter=20, cv=5,\n",
    "    verbose=1, n_jobs=-1, random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Params:\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50d2700",
   "metadata": {},
   "source": [
    "the model training process by using the best hyperparameters, trains the model on the complete dataset, and saves the trained model to disk for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e606e3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_model.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#FINAL TRAINING WITH BEST PARAMS\n",
    "final_model = RandomForestRegressor(**random_search.best_params_, random_state=42)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Save model for reuse\n",
    "joblib.dump(final_model, \"final_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54267c05",
   "metadata": {},
   "source": [
    " loads the test audio filenames from a CSV file, extracts relevant audio features for each file using the extract_features function, and stores these features in a DataFrame for further analysis or model prediction. The shape of the resulting DataFrame is printed to confirm the extraction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b226476e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test features shape: (195, 195)\n"
     ]
    }
   ],
   "source": [
    "# LOAD TEST DATA & EXTRACT FEATURES\n",
    "test_df = pd.read_csv(\"dataset/test.csv\")  \n",
    "filenames = test_df[\"filename\"].tolist()\n",
    "\n",
    "test_features = []\n",
    "\n",
    "for fname in filenames:\n",
    "    path = f\"dataset/audios_test/{fname}\"\n",
    "    feats = extract_features(path)\n",
    "    test_features.append(feats)\n",
    "\n",
    "test_features_df = pd.DataFrame(test_features)\n",
    "print(\"Test features shape:\", test_features_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4e19a5",
   "metadata": {},
   "source": [
    "predicts labels for the test data using the trained final_model, prepares a submission DataFrame containing the filenames and their corresponding predicted labels, and saves this DataFrame to a CSV file named \"submission.csv\" for submission or further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8376af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICT ON TEST DATA\n",
    "predictions = final_model.predict(test_features_df)\n",
    "\n",
    "# Prepare submission\n",
    "submission = pd.DataFrame({\n",
    "    \"filename\": filenames,\n",
    "    \"label\": predictions\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
